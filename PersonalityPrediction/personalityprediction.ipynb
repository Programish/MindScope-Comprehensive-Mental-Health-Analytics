{"metadata":{"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"language":"python","name":"python3","display_name":"Python 3"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":4381,"sourceType":"datasetVersion","datasetId":2637}],"dockerImageVersionId":29661,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# MBTI (Myers-Briggs Type Indicator) RNN","metadata":{}},{"cell_type":"code","source":"!pip show tensorflow","metadata":{"execution":{"iopub.status.busy":"2024-06-16T05:17:45.534348Z","iopub.execute_input":"2024-06-16T05:17:45.535327Z","iopub.status.idle":"2024-06-16T05:17:52.497134Z","shell.execute_reply.started":"2024-06-16T05:17:45.535246Z","shell.execute_reply":"2024-06-16T05:17:52.495926Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"Name: tensorflow\nVersion: 1.14.0\nSummary: TensorFlow is an open source machine learning framework for everyone.\nHome-page: https://www.tensorflow.org/\nAuthor: Google Inc.\nAuthor-email: packages@tensorflow.org\nLicense: Apache 2.0\nLocation: /opt/conda/lib/python3.6/site-packages\nRequires: keras-applications, tensorflow-estimator, gast, absl-py, numpy, grpcio, tensorboard, google-pasta, keras-preprocessing, termcolor, wheel, wrapt, astor, protobuf, six\nRequired-by: fancyimpute\n","output_type":"stream"}]},{"cell_type":"code","source":"# Import Libraries\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\nimport pickle","metadata":{"_cell_guid":"e73d57ef-5ffe-4d4d-8888-4f8840138c1d","_uuid":"2a784050600a9de23bf507d4f1bbe017f8980a29","execution":{"iopub.status.busy":"2024-06-16T08:44:52.602562Z","iopub.execute_input":"2024-06-16T08:44:52.602990Z","iopub.status.idle":"2024-06-16T08:44:54.884373Z","shell.execute_reply.started":"2024-06-16T08:44:52.602918Z","shell.execute_reply":"2024-06-16T08:44:54.883564Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"## Load dataset\n\nThe dataset is a 'csv' file, so we'll use pandas to load it. We shall print the shape and the first few entries of the dataset to understand what we're working with. Accordingly, we need to choose what strategy to use to clean the data.","metadata":{"_cell_guid":"660418a8-9ce6-4e67-afd8-6d0861a9fe1e","_uuid":"ff666f98b54785518bb8aa250524f59facbd50ad"}},{"cell_type":"code","source":"# Load Dataset\ntext=pd.read_csv(\"../input/mbti_1.csv\" ,index_col='type')\nprint(text.shape)\nprint(text[0:5])\nprint(text.iloc[2])","metadata":{"_cell_guid":"781ff4d7-bdfe-4e5d-935d-601e2a2966a5","_uuid":"ac3059a5ebc7fcdd9b38883037d7478363fac32e","execution":{"iopub.status.busy":"2024-06-16T08:44:54.886952Z","iopub.execute_input":"2024-06-16T08:44:54.887306Z","iopub.status.idle":"2024-06-16T08:44:56.272300Z","shell.execute_reply.started":"2024-06-16T08:44:54.887241Z","shell.execute_reply":"2024-06-16T08:44:56.271476Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"(8675, 1)\n                                                  posts\ntype                                                   \nINFJ  'http://www.youtube.com/watch?v=qsXHcwe3krw|||...\nENTP  'I'm finding the lack of me in these posts ver...\nINTP  'Good one  _____   https://www.youtube.com/wat...\nINTJ  'Dear INTP,   I enjoyed our conversation the o...\nENTJ  'You're fired.|||That's another silly misconce...\nposts    'Good one  _____   https://www.youtube.com/wat...\nName: INTP, dtype: object\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Preprocessing labels\nThe neural letwork cannot understand string labels, so we one-hot-encode them using sklearn.preprocessing.LabelBinarizer. I'm displaying the first few labels to see if everything's okay.","metadata":{"_cell_guid":"2d9d8cbf-9871-42c7-9dd8-1c5d5bc47ec2","_uuid":"667feaca9519e2e2d16ce648c258fde2fd3ce247"}},{"cell_type":"code","source":"from sklearn.preprocessing import LabelBinarizer\n\n# One hot encode labels\nlabels=text.index.tolist()\nencoder=LabelBinarizer(neg_label=0, pos_label=1, sparse_output=False)\nlabels=encoder.fit_transform(labels)\nlabels=np.array(labels)\nprint(labels[50:55])","metadata":{"_cell_guid":"bd2c1550-c3e6-4501-9c23-724ccd03b35a","_uuid":"2830e929576f2b7cc0b84faa8cd955dd66dcb655","execution":{"iopub.status.busy":"2024-06-16T08:44:56.274161Z","iopub.execute_input":"2024-06-16T08:44:56.274529Z","iopub.status.idle":"2024-06-16T08:44:57.032487Z","shell.execute_reply.started":"2024-06-16T08:44:56.274458Z","shell.execute_reply":"2024-06-16T08:44:57.031498Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"[[0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0]]\n","output_type":"stream"}]},{"cell_type":"code","source":"mbti_dict={0:'ENFJ',1:'ENFP',2:'ENTJ',3:'ENTP',4:'ESFJ',5:'ESFP',6:'ESTJ',7:'ESTP',8:'INFJ',9:'INFP',10:'INTJ',11:'INTP',12:'ISFJ',13:'ISFP',14:'ISFP',15:'ISTP'}","metadata":{"_cell_guid":"4f7b312c-36ca-41de-80a0-94e382482597","_uuid":"4a7fb67e54ec002ea73368b7bd0895fdaebab778","execution":{"iopub.status.busy":"2024-06-16T08:44:57.033826Z","iopub.execute_input":"2024-06-16T08:44:57.034132Z","iopub.status.idle":"2024-06-16T08:44:57.039076Z","shell.execute_reply.started":"2024-06-16T08:44:57.034075Z","shell.execute_reply":"2024-06-16T08:44:57.038296Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"### Preprocessing posts\n\nWe can see that the posts are very noisy, so they need to be cleaned. For this I'm doing the following:\n\n1. Converting all letters to lowercase.\n2. Remove '|||'\n3. Removing punctuation.\n4. Removing URLs, links etc..\n5. Convert words to integers\n\nWe'll leave unicode emojis alone.","metadata":{"_cell_guid":"f9133062-a98d-4f1b-96d7-d54006241c58","_uuid":"5eddfa6a3100e465ffde1d86b7da0791da3a4d44"}},{"cell_type":"code","source":"import re\n\n# Function to clean data ... will be useful later\ndef post_cleaner(post):\n    \"\"\"cleans individual posts`.\n    Args:\n        post-string\n    Returns:\n         cleaned up post`.\n    \"\"\"\n    # Covert all uppercase characters to lower case\n    post = post.lower() \n    \n    # Remove |||\n    post=post.replace('|||',\"\") \n\n    # Remove URLs, links etc\n    post = re.sub(r'''(?i)\\b((?:https?://|www\\d{0,3}[.]|[a-z0-9.\\-]+[.][a-z]{2,4}/)(?:[^\\s()<>]+|\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\))+(?:\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\)|[^\\s`!()\\[\\]{};:'\".,<>?«»“”‘’]))''', '', post, flags=re.MULTILINE) \n    # This would have removed most of the links but probably not all \n\n    # Remove puntuations \n    puncs1=['@','#','$','%','^','&','*','(',')','-','_','+','=','{','}','[',']','|','\\\\','\"',\"'\",';',':','<','>','/']\n    for punc in puncs1:\n        post=post.replace(punc,'') \n\n    puncs2=[',','.','?','!','\\n']\n    for punc in puncs2:\n        post=post.replace(punc,' ') \n    # Remove extra white spaces\n    post=re.sub( '\\s+', ' ', post ).strip()\n    return post","metadata":{"_cell_guid":"eac653a1-f0da-4f38-96bd-d2be016c1ba0","_uuid":"5918da8ec665950e8133ba22ccbc505ee2a3890f","execution":{"iopub.status.busy":"2024-06-16T08:44:57.042457Z","iopub.execute_input":"2024-06-16T08:44:57.042806Z","iopub.status.idle":"2024-06-16T08:44:57.053143Z","shell.execute_reply.started":"2024-06-16T08:44:57.042744Z","shell.execute_reply":"2024-06-16T08:44:57.052204Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# Clean up posts\n# Covert pandas dataframe object to list. I prefer using lists for prepocessing. \nposts=text.posts.tolist()\nposts=[post_cleaner(post) for post in posts]","metadata":{"_cell_guid":"8739bc1c-f158-4f10-9130-67a8ac6415a8","_uuid":"1a9248e49f19347c38b33c0d3f5612fb56e9ff7b","execution":{"iopub.status.busy":"2024-06-16T08:44:57.055058Z","iopub.execute_input":"2024-06-16T08:44:57.055406Z","iopub.status.idle":"2024-06-16T08:45:39.790455Z","shell.execute_reply.started":"2024-06-16T08:44:57.055342Z","shell.execute_reply":"2024-06-16T08:45:39.789715Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# Count total words\nfrom collections import Counter\n\nword_count=Counter()\nfor post in posts:\n    word_count.update(post.split(\" \"))","metadata":{"_cell_guid":"c5189ad3-ab59-4eee-a33a-82b7bdd398ea","_uuid":"e086424b857f002373c5eabe0fb2b6f7b57970e7","execution":{"iopub.status.busy":"2024-06-16T08:45:39.791799Z","iopub.execute_input":"2024-06-16T08:45:39.792058Z","iopub.status.idle":"2024-06-16T08:45:42.158784Z","shell.execute_reply.started":"2024-06-16T08:45:39.792020Z","shell.execute_reply":"2024-06-16T08:45:42.158016Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# Size of the vocabulary available to the RNN\nvocab_len=len(word_count)\nprint(vocab_len)\n\nprint(len(posts[0]))","metadata":{"_cell_guid":"6f07ebbd-72e1-47c8-9919-1739d570e29d","_uuid":"2e6a8dcc20e16775f1dfa2e1e5eec1c8e658074c","execution":{"iopub.status.busy":"2024-06-16T08:45:42.160102Z","iopub.execute_input":"2024-06-16T08:45:42.160352Z","iopub.status.idle":"2024-06-16T08:45:42.165104Z","shell.execute_reply.started":"2024-06-16T08:45:42.160310Z","shell.execute_reply":"2024-06-16T08:45:42.164159Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"172984\n3094\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Convert words to integers","metadata":{"_cell_guid":"9ee928c4-efc4-4e9d-86dc-86e1ba0f33ca","_uuid":"47c81752a05c0ec56f879ff4b7c5222d584f4d16"}},{"cell_type":"code","source":"# Create a look up table \nvocab = sorted(word_count, key=word_count.get, reverse=True)\n# Create your dictionary that maps vocab words to integers here\nvocab_to_int = {word: ii for ii, word in enumerate(vocab, 1)}\n\nposts_ints=[]\nfor post in posts:\n    posts_ints.append([vocab_to_int[word] for word in post.split()])\n\nprint(posts_ints[0])\nprint(len(posts_ints[0]))","metadata":{"_cell_guid":"88818f1e-a2fa-4da9-bb7d-3cc395e8d8af","_uuid":"3010bfa3dbf515ac65bbdb6c46f87e5d50a9e10b","execution":{"iopub.status.busy":"2024-06-16T08:45:42.166430Z","iopub.execute_input":"2024-06-16T08:45:42.166958Z","iopub.status.idle":"2024-06-16T08:45:44.974814Z","shell.execute_reply.started":"2024-06-16T08:45:42.166663Z","shell.execute_reply":"2024-06-16T08:45:44.973854Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"[5, 141, 1287, 61293, 22, 703, 1850, 2069, 61294, 89, 72, 2, 84, 13390, 286, 11, 39, 108, 24, 2176, 14, 84, 6, 375, 196, 2, 723, 286, 12342, 7, 2, 241, 115, 12, 133, 148, 574, 24, 134, 1035, 185, 5881, 2140, 2, 459, 189, 762, 11, 61295, 61296, 279, 3, 416, 6, 39, 7396, 34, 86, 814, 14, 4, 238, 3, 22, 20, 3969, 43, 2, 59, 11, 217, 475, 6, 1558, 154, 3, 524, 2, 205, 242, 26, 242, 6, 2559, 26, 61297, 61298, 308, 5, 274, 492, 712, 1216, 12655, 61299, 41, 257, 7322, 987, 6, 1077, 39, 3300, 5, 1, 31, 161, 1077, 64, 169, 1108, 11, 39, 130, 2803, 3858, 1989, 11, 7024, 150, 154, 28515, 26, 4, 5882, 2233, 510, 211, 62, 16, 565, 3459, 443, 2804, 8, 309, 95, 32, 6508, 218, 7, 81, 3, 33, 49, 47, 90, 408, 221, 626, 309, 218, 630, 342, 5, 4236, 40, 532, 73, 43, 76, 11, 7024, 5185, 9, 1027, 4, 464, 492, 5, 4, 75, 46, 41, 8, 940, 4, 75, 46, 41, 8, 9, 833, 1489, 11, 8, 1, 56, 22, 354, 10262, 2, 684, 6, 111, 626, 11286, 613, 194, 35, 103, 39, 417, 464, 568, 1120, 62, 5, 35, 21, 39, 92, 954, 417, 464, 568, 389, 2038, 3, 20, 70, 688, 61300, 98, 52, 63, 14, 206, 641, 1, 136, 1226, 27, 4, 75, 115, 1, 29, 7025, 2, 59, 6, 3799, 2690, 1, 13798, 807, 12, 1200, 191, 47, 2517, 84, 77, 59, 135, 20, 24052, 29, 305, 2, 17, 59, 169, 7, 42, 31, 789, 38, 85, 93, 20, 149, 3, 2713, 237, 2772, 30, 99, 114, 4, 12021, 243, 71, 415, 40, 39, 778, 303, 5336, 9, 8314, 301, 927, 5, 91, 88, 7, 3449, 9909, 988, 1, 48, 3067, 2, 251, 55, 16828, 3, 61301, 54, 19, 152, 2070, 10, 6, 17, 53, 289, 11, 7914, 10067, 5, 663, 28516, 11, 7914, 169, 7634, 143, 80, 1368, 2017, 73, 16829, 5, 5288, 14, 70, 138, 2511, 11, 8, 1638, 51, 105, 7, 37, 6, 2, 1186, 2805, 14, 556, 717, 11, 2, 2174, 16, 2, 44462, 2805, 54, 1295, 570, 934, 1738, 7, 273, 36, 5789, 1731, 2805, 14, 4, 340, 5260, 6, 661, 177, 1223, 7915, 24, 532, 5, 122, 31809, 24, 4, 20075, 11, 2, 810, 176, 360, 100, 195, 1588, 177, 19078, 5151, 4506, 3057, 15607, 24, 100, 11517, 4097, 5151, 1437, 235, 1, 82, 10, 26, 4, 3171, 191, 25, 133, 742, 206, 1426, 25, 61302, 43, 2371, 21, 2371, 54, 45, 1235, 34, 2, 252, 8, 2750, 11, 5531, 80, 6, 39, 195, 23, 4, 2111, 308, 3, 2, 2537, 8212, 126, 66, 36641, 12, 2867, 2228, 18, 22, 25, 7714, 2111, 1662, 23, 1796, 61303, 14, 447, 43, 2, 585, 646, 12, 886, 1196, 1398, 426, 3, 490, 16, 2, 19079, 14, 69, 70, 68, 6, 4, 36642, 44463, 168, 6, 4135, 1088, 2944, 321, 289, 222, 278, 1, 324, 489, 11, 2395, 1831, 4, 941, 777, 570, 4, 170, 156, 319, 5, 57, 374, 6, 672, 35, 1, 105, 33, 174, 103, 1, 3, 20, 11, 8, 1197, 276, 4, 327, 251, 6, 12, 2560, 27, 29, 26049, 101, 16, 70, 1, 23, 19, 1328, 3111, 246, 4, 2680, 141, 73, 2, 79, 3, 2, 11759, 1188, 5, 293, 4, 209, 108, 14, 101]\n566\n","output_type":"stream"}]},{"cell_type":"markdown","source":" ### Make posts uniform\nWe can see that the lengths of the posts aren't uniform, so we'll limit number of words in each post to 1000.For posts with less than 1000 words, we'll pad with zeros.","metadata":{"_cell_guid":"cd4a1482-b863-4c26-ae92-ce20b8ff3766","_uuid":"2d640b383ddf3d75caffc2dc7cef95c19a009aac"}},{"cell_type":"code","source":"posts_lens = Counter([len(x) for x in posts])\nprint(\"Zero-length reviews: {}\".format(posts_lens[0]))\nprint(\"Maximum review length: {}\".format(max(posts_lens)))\nprint(\"Minimum review length: {}\".format(min(posts_lens)))\n\nseq_len = 500\nfeatures=np.zeros((len(posts_ints),seq_len),dtype=int)\nfor i, row in enumerate(posts_ints):\n    features[i, -len(row):] = np.array(row)[:seq_len]\nprint(features[:10])","metadata":{"_cell_guid":"8709d94d-b98e-49dc-8b35-4a3fffca1673","_uuid":"64538831d8bb2a7422be33997b1dda3207d21b9f","execution":{"iopub.status.busy":"2024-06-16T08:45:44.976061Z","iopub.execute_input":"2024-06-16T08:45:44.976309Z","iopub.status.idle":"2024-06-16T08:45:45.996239Z","shell.execute_reply.started":"2024-06-16T08:45:44.976267Z","shell.execute_reply":"2024-06-16T08:45:45.995451Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Zero-length reviews: 0\nMaximum review length: 9588\nMinimum review length: 13\n[[   5  141 1287 ...  222  278    1]\n [  18  751    2 ...    2 1660 4189]\n [  75   46  386 ...   24 2234   75]\n ...\n [   1  259    3 ...   17  631    3]\n [  18   22  120 ... 4330  659   11]\n [  11   19 1197 ...   47 2496  112]]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Preparing tranining, test and validation datasets","metadata":{"_cell_guid":"12148723-9ab3-4dc6-8971-4d8ac41f7b58","_uuid":"7a643d0c8443884ef03c9b618369098b606d51bc"}},{"cell_type":"code","source":"# Split data into training, test and validation\n\nsplit_frac = 0.8\n\nnum_ele=int(split_frac*len(features))\nrem_ele=len(features)-num_ele\ntrain_x, val_x = features[:num_ele],features[num_ele:int(rem_ele/2)+num_ele]\ntrain_y, val_y = labels[:num_ele],labels[num_ele:int(rem_ele/2)+num_ele]\n\ntest_x =features[num_ele+int(rem_ele/2):]\ntest_y = labels[num_ele+int(rem_ele/2):]\n\nprint(\"\\t\\t\\tFeature Shapes:\")\nprint(\"Train set: \\t\\t{}\".format(train_x.shape), \n      \"\\nValidation set: \\t{}\".format(val_x.shape),\n      \"\\nTest set: \\t\\t{}\".format(test_x.shape))","metadata":{"_cell_guid":"aacacf26-4ab3-45bb-9f6f-f5353afda760","_uuid":"6c29d68316001a6cf4d64acd4f0f932e4fcce804","execution":{"iopub.status.busy":"2024-06-16T08:45:45.997601Z","iopub.execute_input":"2024-06-16T08:45:45.997921Z","iopub.status.idle":"2024-06-16T08:45:46.007335Z","shell.execute_reply.started":"2024-06-16T08:45:45.997843Z","shell.execute_reply":"2024-06-16T08:45:46.006544Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"\t\t\tFeature Shapes:\nTrain set: \t\t(6940, 500) \nValidation set: \t(867, 500) \nTest set: \t\t(868, 500)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## The RNN","metadata":{"_cell_guid":"c21961f3-e8b3-42de-b4d2-5542226036f4","_uuid":"72a85f118ed44f53fffa6f83465ca80b54cfdf1a"}},{"cell_type":"code","source":"lstm_size = 256\nlstm_layers = 1\nbatch_size = 256\nlearning_rate = 0.01\nembed_dim=250","metadata":{"_cell_guid":"3a82d5ed-0199-4e7f-9b18-2ea953bfc195","_uuid":"c25c324b578e7d8e4faf31d6eb9265759bf8663d","execution":{"iopub.status.busy":"2024-06-16T08:45:46.011060Z","iopub.execute_input":"2024-06-16T08:45:46.011408Z","iopub.status.idle":"2024-06-16T08:45:46.018190Z","shell.execute_reply.started":"2024-06-16T08:45:46.011346Z","shell.execute_reply":"2024-06-16T08:45:46.017257Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"n_words = len(vocab_to_int) + 1 # Adding 1 because we use 0's for padding, dictionary started at 1\n\n# Create the graph object\ngraph = tf.Graph()\n# Add nodes to the graph\nwith graph.as_default():\n    input_data = tf.placeholder(tf.int32, [None, None], name='inputs')\n    labels_ = tf.placeholder(tf.int32, [None, None], name='labels')\n    keep_prob = tf.placeholder(tf.float32, name='keep_prob')","metadata":{"_cell_guid":"6cc632c5-174f-459d-be3a-511f1d6e89ec","_uuid":"70ba0c6ea9268fcdb4024de80797b24711f46cb1","execution":{"iopub.status.busy":"2024-06-16T08:45:46.019526Z","iopub.execute_input":"2024-06-16T08:45:46.019824Z","iopub.status.idle":"2024-06-16T08:45:46.058218Z","shell.execute_reply.started":"2024-06-16T08:45:46.019772Z","shell.execute_reply":"2024-06-16T08:45:46.057516Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"n_words","metadata":{"execution":{"iopub.status.busy":"2024-06-16T08:45:46.059945Z","iopub.execute_input":"2024-06-16T08:45:46.060295Z","iopub.status.idle":"2024-06-16T08:45:46.068008Z","shell.execute_reply.started":"2024-06-16T08:45:46.060232Z","shell.execute_reply":"2024-06-16T08:45:46.067004Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"172985"},"metadata":{}}]},{"cell_type":"code","source":"# Embedding\nwith graph.as_default():\n    embedding= tf.Variable(tf.random_uniform(shape=(n_words,embed_dim),minval=-1,maxval=1))\n    embed=tf.nn.embedding_lookup(embedding,input_data)\n    print(embed.shape)","metadata":{"_cell_guid":"5c176a7f-863a-4ad5-b982-d90f2a657edd","_uuid":"8a3df7fee93677bf1deea55566cdeb792c8bb9ab","execution":{"iopub.status.busy":"2024-06-16T08:45:46.069258Z","iopub.execute_input":"2024-06-16T08:45:46.069533Z","iopub.status.idle":"2024-06-16T08:45:46.093139Z","shell.execute_reply.started":"2024-06-16T08:45:46.069468Z","shell.execute_reply":"2024-06-16T08:45:46.092344Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"(?, ?, 250)\n","output_type":"stream"}]},{"cell_type":"code","source":"# LSTM cell\nwith graph.as_default():\n    # basic LSTM cell\n    lstm = tf.contrib.rnn.BasicLSTMCell(lstm_size)\n    \n    # Add dropout to the cell\n    drop = tf.contrib.rnn.DropoutWrapper(lstm,output_keep_prob=keep_prob)\n    \n    # Stack up multiple LSTM layers, for deep learning\n    cell = tf.contrib.rnn.MultiRNNCell([drop]* lstm_layers)\n    \n    # Getting an initial state of all zeros\n    initial_state = cell.zero_state(batch_size, tf.float32)","metadata":{"_cell_guid":"4541e896-1fd1-4c87-abf6-84434984ca28","_uuid":"169693e69c9fd6399bf0cfb2e63793b0f1d11bf8","execution":{"iopub.status.busy":"2024-06-16T08:45:46.094831Z","iopub.execute_input":"2024-06-16T08:45:46.095222Z","iopub.status.idle":"2024-06-16T08:45:48.171106Z","shell.execute_reply.started":"2024-06-16T08:45:46.095156Z","shell.execute_reply":"2024-06-16T08:45:48.170278Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"with graph.as_default():\n    outputs,final_state=tf.nn.dynamic_rnn(cell,embed,dtype=tf.float32 )","metadata":{"_cell_guid":"ea851977-2d38-4570-b8e6-92b9a3285b7a","_uuid":"09ed7b0f4435c6b6011d89b43cb59bafaef60727","execution":{"iopub.status.busy":"2024-06-16T08:45:48.172683Z","iopub.execute_input":"2024-06-16T08:45:48.173050Z","iopub.status.idle":"2024-06-16T08:45:48.516323Z","shell.execute_reply.started":"2024-06-16T08:45:48.172985Z","shell.execute_reply":"2024-06-16T08:45:48.515635Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"WARNING: Entity <bound method MultiRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.MultiRNNCell object at 0x7c0ff4a47cf8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.MultiRNNCell object at 0x7c0ff4a47cf8>>: AttributeError: module 'gast' has no attribute 'Num'\nWARNING: Entity <bound method BasicLSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x7c0ff4a33f98>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BasicLSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x7c0ff4a33f98>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","output_type":"stream"}]},{"cell_type":"code","source":"with graph.as_default():\n    \n    pre = tf.layers.dense(outputs[:,-1], 16, activation=tf.nn.relu)\n    predictions=tf.layers.dense(pre, 16, activation=tf.nn.softmax)\n    \n    cost = tf.losses.mean_squared_error(labels_, predictions)\n    optimizer = tf.train.AdamOptimizer(learning_rate).minimize(cost)","metadata":{"_cell_guid":"81b02a11-40c2-4784-a781-21e081e21711","_uuid":"11e30ca0ef0c3936e792c0d2b47a9a2898ef8d59","execution":{"iopub.status.busy":"2024-06-16T08:45:48.517512Z","iopub.execute_input":"2024-06-16T08:45:48.517779Z","iopub.status.idle":"2024-06-16T08:45:49.347565Z","shell.execute_reply.started":"2024-06-16T08:45:48.517733Z","shell.execute_reply":"2024-06-16T08:45:49.346804Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7c0fe2b01b38>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7c0fe2b01b38>>: AssertionError: Bad argument number for Name: 3, expecting 4\nWARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7c0fe2b01b38>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7c0fe2b01b38>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","output_type":"stream"}]},{"cell_type":"code","source":"with graph.as_default():\n    correct_pred = tf.equal(tf.cast(tf.round(predictions), tf.int32), labels_)\n    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))","metadata":{"_cell_guid":"2b622b23-98c4-430e-8b62-298c75774ad5","_uuid":"c48275ff698a96edb1b9440315fc67a228666a3f","execution":{"iopub.status.busy":"2024-06-16T08:45:49.349017Z","iopub.execute_input":"2024-06-16T08:45:49.349267Z","iopub.status.idle":"2024-06-16T08:45:49.360595Z","shell.execute_reply.started":"2024-06-16T08:45:49.349225Z","shell.execute_reply":"2024-06-16T08:45:49.359815Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"def get_batches(x, y, batch_size=100):    \n    n_batches = len(x)//batch_size\n    x, y = x[:n_batches*batch_size], y[:n_batches*batch_size]\n    for ii in range(0, len(x), batch_size):\n        yield x[ii:ii+batch_size], y[ii:ii+batch_size]","metadata":{"_cell_guid":"332bbb71-84bb-4a45-93da-a9f28d48245d","_uuid":"ed6008ad6bf6d88724523e948aba01a4f649aad7","execution":{"iopub.status.busy":"2024-06-16T08:45:49.362166Z","iopub.execute_input":"2024-06-16T08:45:49.362419Z","iopub.status.idle":"2024-06-16T08:45:49.368789Z","shell.execute_reply.started":"2024-06-16T08:45:49.362377Z","shell.execute_reply":"2024-06-16T08:45:49.367805Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":"## Training","metadata":{"_cell_guid":"2c58430c-e36d-4170-88fc-eb6468818d94","_uuid":"aeaadce1ec744f315b4edf025e4e752b21e066e0"}},{"cell_type":"code","source":"epochs = 3\n\nwith graph.as_default():\n    saver = tf.train.Saver()\n\nwith tf.Session(graph=graph) as sess:\n    sess.run(tf.global_variables_initializer())\n    iteration = 1\n    for e in range(epochs):\n        state = sess.run(initial_state)\n        \n        for ii, (x, y) in enumerate(get_batches(train_x, train_y, batch_size), 1):\n            feed = {input_data: x,\n                    labels_: y,\n                    keep_prob: 1.0,\n                    initial_state: state}\n            loss, state, _ = sess.run([cost, final_state, optimizer], feed_dict=feed)\n            \n            if iteration%5==0:\n                print(\"Epoch: {}/{}\".format(e, epochs),\n                      \"Iteration: {}\".format(iteration),\n                      \"Train loss: {:.3f}\".format(loss))\n\n            if iteration%25==0:\n                val_acc = []\n                val_state = sess.run(cell.zero_state(batch_size, tf.float32))\n                for x, y in get_batches(val_x, val_y, batch_size):\n                    feed = {input_data: x,\n                            labels_: y,\n                            keep_prob: 1,\n                            initial_state: val_state}\n                    batch_acc, val_state = sess.run([accuracy, final_state], feed_dict=feed)\n                    val_acc.append(batch_acc)\n                print(\"Val acc: {:.3f}\".format(np.mean(val_acc)))\n            iteration +=1\n    saver.save(sess, \"checkpoints/mbti.ckpt\")","metadata":{"_cell_guid":"f27e94a0-d21f-4885-8aba-133079a61352","_uuid":"0110900f97830864943c05a48b6998bcc3afb74d","execution":{"iopub.status.busy":"2024-06-16T08:45:49.370049Z","iopub.execute_input":"2024-06-16T08:45:49.370497Z","iopub.status.idle":"2024-06-16T08:54:05.741563Z","shell.execute_reply.started":"2024-06-16T08:45:49.370330Z","shell.execute_reply":"2024-06-16T08:54:05.740635Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"Epoch: 0/3 Iteration: 5 Train loss: 0.058\nEpoch: 0/3 Iteration: 10 Train loss: 0.057\nEpoch: 0/3 Iteration: 15 Train loss: 0.057\nEpoch: 0/3 Iteration: 20 Train loss: 0.056\nEpoch: 0/3 Iteration: 25 Train loss: 0.055\nVal acc: 0.938\nEpoch: 1/3 Iteration: 30 Train loss: 0.054\nEpoch: 1/3 Iteration: 35 Train loss: 0.056\nEpoch: 1/3 Iteration: 40 Train loss: 0.055\nEpoch: 1/3 Iteration: 45 Train loss: 0.052\nEpoch: 1/3 Iteration: 50 Train loss: 0.052\nVal acc: 0.937\nEpoch: 2/3 Iteration: 55 Train loss: 0.051\nEpoch: 2/3 Iteration: 60 Train loss: 0.051\nEpoch: 2/3 Iteration: 65 Train loss: 0.052\nEpoch: 2/3 Iteration: 70 Train loss: 0.050\nEpoch: 2/3 Iteration: 75 Train loss: 0.048\nVal acc: 0.933\nEpoch: 2/3 Iteration: 80 Train loss: 0.045\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Testing","metadata":{"_cell_guid":"0c39f046-f8a1-47a2-8029-71be84beabea","_uuid":"2bd79323f22ae74baf66c695c7ff65c426eadaaa"}},{"cell_type":"code","source":"test_acc = []\nwith tf.Session(graph=graph) as sess:\n    saver.restore(sess, tf.train.latest_checkpoint('checkpoints'))\n    test_state = sess.run(cell.zero_state(batch_size, tf.float32))\n    for ii, (x, y) in enumerate(get_batches(test_x, test_y, batch_size), 1):\n        feed = {input_data: x,\n                labels_: y,\n                keep_prob: 1,\n                initial_state: test_state}\n        batch_acc, test_state = sess.run([accuracy, final_state], feed_dict=feed)\n        test_acc.append(batch_acc)\n    print(\"Test accuracy: {:.3f}\".format(np.mean(test_acc)))","metadata":{"_cell_guid":"3f2aba5c-346e-4c06-ba21-40d0b31d3b05","_uuid":"b23cef1239627fd2333091ee5a131772df7d95e4","execution":{"iopub.status.busy":"2024-06-15T09:38:30.955389Z","iopub.execute_input":"2024-06-15T09:38:30.955686Z","iopub.status.idle":"2024-06-15T09:38:36.795754Z","shell.execute_reply.started":"2024-06-15T09:38:30.955639Z","shell.execute_reply":"2024-06-15T09:38:36.794783Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"Test accuracy: 0.937\n","output_type":"stream"}]},{"cell_type":"code","source":"import pickle\n\n# Save the vocab_to_int dictionary\nwith open('vocab_to_int.pickle', 'wb') as handle:\n    pickle.dump(vocab_to_int, handle, protocol=pickle.HIGHEST_PROTOCOL)","metadata":{"execution":{"iopub.status.busy":"2024-06-16T09:14:59.713779Z","iopub.execute_input":"2024-06-16T09:14:59.714237Z","iopub.status.idle":"2024-06-16T09:14:59.769027Z","shell.execute_reply.started":"2024-06-16T09:14:59.714177Z","shell.execute_reply":"2024-06-16T09:14:59.767931Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"# After training, save the model\noutput_dir = '/kaggle/working/'\nwith tf.Session(graph=graph) as sess:\n    sess.run(tf.global_variables_initializer())  # Initialize all variables\n    saver.save(sess, output_dir + \"mbti.ckpt\")\n","metadata":{"_cell_guid":"86513a17-0d1f-447c-b66e-80d741b932d0","_uuid":"8fb9ea36415a03d44412bcc7686f92fe0b8249fe","execution":{"iopub.status.busy":"2024-06-16T08:59:08.218560Z","iopub.execute_input":"2024-06-16T08:59:08.218927Z","iopub.status.idle":"2024-06-16T08:59:11.043839Z","shell.execute_reply.started":"2024-06-16T08:59:08.218865Z","shell.execute_reply":"2024-06-16T08:59:11.042689Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"# Reload the saved model\nwith tf.Session(graph=graph) as sess:\n    saver.restore(sess, output_dir + \"mbti.ckpt\")\n\n    # Example of making predictions\n    test_state = sess.run(cell.zero_state(batch_size, tf.float32))\n    test_predictions = []\n    for x, y in get_batches(test_x, test_y, batch_size):\n        feed = {input_data: x,\n                labels_: y,\n                keep_prob: 1,\n                initial_state: test_state}\n        batch_predictions, test_state = sess.run([predictions, final_state], feed_dict=feed)\n        test_predictions.extend(batch_predictions.argmax(axis=1))\n\n    # Convert predicted indices back to labels\n    predicted_labels = [mbti_dict[i] for i in test_predictions]\n\n    # Process predicted_labels as needed for your application\n    print(\"Predicted labels:\", predicted_labels)\n","metadata":{"execution":{"iopub.status.busy":"2024-06-15T10:06:47.059207Z","iopub.execute_input":"2024-06-15T10:06:47.059628Z","iopub.status.idle":"2024-06-15T10:06:53.182040Z","shell.execute_reply.started":"2024-06-15T10:06:47.059574Z","shell.execute_reply":"2024-06-15T10:06:53.180706Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"Predicted labels: ['ESTP', 'ESTJ', 'ENFJ', 'ESTJ', 'ENTJ', 'ENFJ', 'ESTJ', 'ENTP', 'ESTJ', 'ESTJ', 'ESTP', 'ESTJ', 'ESFJ', 'ESFJ', 'ESFJ', 'ENTP', 'ESTP', 'ISFP', 'ESTP', 'ESTJ', 'ESTP', 'ESTP', 'INFP', 'ESTP', 'ESTJ', 'ENFJ', 'ESTP', 'ESTP', 'ISFP', 'ESTJ', 'ESFJ', 'ENTJ', 'ISFP', 'ESTP', 'INFP', 'ESFP', 'ENTJ', 'ENFJ', 'ENTJ', 'ESFJ', 'ESTP', 'ESTP', 'INFJ', 'ESTP', 'ESFJ', 'ENFJ', 'ESTJ', 'INTP', 'ENTJ', 'INFJ', 'ESFP', 'INFJ', 'ESTP', 'ESTJ', 'ENTJ', 'ESTP', 'ENFJ', 'ENTP', 'ESTP', 'ISFP', 'ENTJ', 'ESTP', 'ESTJ', 'ENTP', 'ENFJ', 'ENFJ', 'INFJ', 'ENTP', 'ESTJ', 'INFP', 'ENFJ', 'ESTJ', 'ESFJ', 'ESFJ', 'ESFP', 'ESFJ', 'ENFJ', 'ESTJ', 'INFP', 'ESFJ', 'ESTP', 'ESTP', 'ESFP', 'ESTJ', 'ESFJ', 'ESTJ', 'ENTJ', 'ESTP', 'ESTJ', 'ENFJ', 'ENTJ', 'INFP', 'ESTJ', 'ESTJ', 'ESTP', 'ENTP', 'ISFP', 'ESTJ', 'ESTP', 'ESTJ', 'ENFJ', 'ESTJ', 'ESTP', 'ESTP', 'ENTJ', 'ENTJ', 'ESTJ', 'ESFJ', 'ENFJ', 'ENFJ', 'INFP', 'ESTJ', 'INFP', 'ENTJ', 'INFJ', 'ENTJ', 'ESTP', 'ESFJ', 'ESTJ', 'ESFJ', 'ESFJ', 'ESTJ', 'ESTP', 'ESTP', 'ISFP', 'ENFJ', 'ESTJ', 'ENFJ', 'ESFP', 'ESTJ', 'ESTP', 'ENFJ', 'ESTJ', 'ENTP', 'ESTP', 'ESFJ', 'ESFJ', 'ENTJ', 'ESTJ', 'ENFJ', 'ESTP', 'ENFJ', 'ESTJ', 'INTP', 'ISFP', 'ESTJ', 'ESTJ', 'ESFP', 'ESTJ', 'ESTJ', 'INFJ', 'ENTJ', 'ESTJ', 'ESFP', 'ESFJ', 'ESTJ', 'ESTJ', 'ESTJ', 'ENFJ', 'ENFJ', 'ESTJ', 'ESTP', 'INFJ', 'ESTJ', 'ESTP', 'ENFJ', 'ESFJ', 'ESFJ', 'ESFJ', 'ESTJ', 'ESTJ', 'ESTJ', 'ESTJ', 'ENFJ', 'ESFJ', 'ENTP', 'ENTJ', 'ESTP', 'ENTJ', 'ESTJ', 'ESTJ', 'ENTP', 'ESTP', 'ESTJ', 'ESFJ', 'ESTJ', 'INFP', 'ENTJ', 'ESTJ', 'ESTJ', 'ESTJ', 'ENTJ', 'ENTJ', 'ESTP', 'ESFJ', 'ENTJ', 'ESTJ', 'ESTJ', 'ESTP', 'ENFJ', 'ENTP', 'ENTP', 'ESFP', 'ESTJ', 'ESTJ', 'ESTJ', 'ENTP', 'INFP', 'ENTJ', 'ENFJ', 'ENTP', 'ESTJ', 'ESTP', 'ESFJ', 'INTP', 'ESTJ', 'ESTP', 'ESTJ', 'ESTP', 'ENTJ', 'INTP', 'ESTP', 'ESTP', 'ESTP', 'ESTP', 'ESTJ', 'ESFJ', 'ENFJ', 'ESTJ', 'ESTP', 'ENTJ', 'INFJ', 'ESTP', 'ENTP', 'ISFP', 'ISFP', 'ENTJ', 'ESTJ', 'INFP', 'ESFJ', 'ISFP', 'INFP', 'INFJ', 'ESTJ', 'ISFP', 'ENTP', 'ESFP', 'INFJ', 'ESTJ', 'ESTJ', 'ESTJ', 'ENTP', 'ESTJ', 'ESTP', 'ESTJ', 'ENFJ', 'INFP', 'ENFJ', 'ISFP', 'ESTJ', 'ESTJ', 'ESFJ', 'INFJ', 'ESTJ', 'ENTJ', 'ISFP', 'ESTP', 'ESFP', 'ESFJ', 'ESTJ', 'INFJ', 'ESTJ', 'ESTJ', 'ENFJ', 'ENTJ', 'ESTP', 'ENFJ', 'ESFJ', 'INFJ', 'INFJ', 'ESTP', 'ESTP', 'ESTJ', 'ESTP', 'ESTP', 'ESFJ', 'ESFP', 'ESTP', 'ESTJ', 'ESTJ', 'ENFJ', 'ESFP', 'ENFJ', 'ENTP', 'ESTJ', 'ENFJ', 'ENFJ', 'ESTJ', 'ESTP', 'ESTP', 'ESFJ', 'INFJ', 'ESTJ', 'ESTP', 'ESTJ', 'ENFJ', 'ESTP', 'ESTJ', 'ENTP', 'ENFJ', 'ESFJ', 'ESTJ', 'ESTP', 'ESTP', 'ESTJ', 'ESTJ', 'ENFJ', 'ESTJ', 'ESFJ', 'ESTJ', 'ESTP', 'ESTP', 'ENFJ', 'ESTP', 'ESTJ', 'ESTP', 'ESFJ', 'ENFJ', 'INFJ', 'ESTJ', 'ENFJ', 'ENFJ', 'INTP', 'ENFJ', 'ENFJ', 'ESTP', 'ISFP', 'ESTJ', 'ESTP', 'ESTP', 'ENFJ', 'ESTJ', 'ESTP', 'INFJ', 'ENFJ', 'ENTJ', 'INFP', 'ENTP', 'ESFJ', 'INTP', 'ENTJ', 'ESTJ', 'ENTP', 'INFJ', 'ESTJ', 'ESTJ', 'ESTJ', 'ESTJ', 'ENFJ', 'ENTP', 'ENFJ', 'ESTJ', 'INFJ', 'INTJ', 'ESFJ', 'ENTJ', 'ESTJ', 'ESTJ', 'ESTP', 'ESTP', 'ENTJ', 'ESTJ', 'ISFP', 'ESTJ', 'ENTJ', 'ISFP', 'ENFJ', 'ESTJ', 'ESTJ', 'ESTJ', 'ESTJ', 'INTP', 'ESTJ', 'ENTJ', 'ESTP', 'ENTP', 'ESTJ', 'ESTP', 'ENTJ', 'ESTJ', 'ENFJ', 'ESTJ', 'ENFJ', 'INFP', 'ESTP', 'ESFJ', 'ISFP', 'ESTJ', 'ESTJ', 'ESFJ', 'ISFP', 'ESTP', 'ESTJ', 'ENTP', 'ENFJ', 'ENTJ', 'INFJ', 'ENFJ', 'ESTJ', 'ESTP', 'ESTP', 'ESTJ', 'ISFP', 'ESTP', 'ESTJ', 'ESTP', 'ESTP', 'INFJ', 'ISFP', 'ENFJ', 'ESFJ', 'ENFJ', 'ENFJ', 'INFP', 'ENTP', 'ENTP', 'ENTP', 'ESTJ', 'ESFJ', 'ESTJ', 'ESFJ', 'INFJ', 'ENTP', 'ENTJ', 'ESTJ', 'ESTJ', 'ENTP', 'ESTJ', 'INTP', 'ESTJ', 'ESTP', 'ESFP', 'ENTP', 'ESTP', 'ESTJ', 'INTP', 'ESTP', 'ENFJ', 'ESTP', 'ESTJ', 'ESTP', 'ESTJ', 'ENTJ', 'ESFJ', 'ESTJ', 'ESTJ', 'ESTJ', 'ESFJ', 'ESTP', 'ESTJ', 'ESTJ', 'ESTP', 'ENTP', 'ENTP', 'ENFJ', 'ENTJ', 'ESTP', 'INFJ', 'ESTJ', 'ESTP', 'ESTJ', 'ESFJ', 'ISFP', 'ESTJ', 'INTP', 'ENFJ', 'ESFJ', 'ESTP', 'ENFJ', 'ENFJ', 'INTJ', 'ESTJ', 'ISFP', 'ESTJ', 'ESTP', 'ESTJ', 'ESTJ', 'ENTP', 'ESTJ', 'ESTJ', 'ESTJ', 'ESTP', 'ESFJ', 'ESTJ', 'ESTP', 'ESTP', 'ESTJ', 'ESTP', 'ENTP', 'ESTJ', 'ISFP', 'ENFJ', 'ESTP', 'INFP', 'ENTJ', 'ESTP', 'ESTJ', 'INFJ', 'ESTJ', 'ESTP', 'ESTJ', 'ENTJ', 'ESTJ', 'ENTJ', 'ESTJ', 'ESTP', 'ESTJ', 'ENFJ', 'ESTP', 'ENFJ', 'ESTJ', 'ESFP', 'INFP', 'ESFP', 'ESTJ', 'ENTJ', 'ESTJ', 'ESTP', 'ESTP', 'ESFJ', 'ISFP', 'ESTP', 'ENFJ', 'ENTP', 'ESFJ', 'ESTJ', 'ESTJ', 'ESTP', 'ENFJ', 'ESTJ', 'ESTP', 'ESTJ', 'ESFJ', 'ESTP', 'ENFJ', 'ESFJ', 'ENFJ', 'ISFP', 'ENTP', 'ESFJ', 'ESTJ', 'ENFJ', 'ENFJ', 'ESFJ', 'ENFJ', 'ENFJ', 'ESFJ', 'ESTJ', 'INFP', 'ENFJ', 'ESTJ', 'INFJ', 'ESFJ', 'ESTJ', 'ESTP', 'ESFJ', 'ESTP', 'ESTJ', 'ENFJ', 'ESTJ', 'ESTJ', 'ESTP', 'ESTJ', 'ESFJ', 'ISFP', 'ESTJ', 'INFJ', 'ESTJ', 'INTP', 'ESTJ', 'ESFJ', 'ESTP', 'INFJ', 'ESFP', 'ESTP', 'INTP', 'ESTJ', 'ESTJ', 'INFP', 'INTP', 'ESTJ', 'ENTP', 'ESTP', 'ESTP', 'ESTJ', 'ESTJ', 'INTJ', 'ESTJ', 'ESTP', 'ESTJ', 'ISFP', 'ESTJ', 'ESFP', 'ENFJ', 'ESTJ', 'ISFP', 'ESTJ', 'ESTP', 'ESTJ', 'ISFP', 'ESTP', 'ISFP', 'ESFP', 'ESTJ', 'ENTP', 'ESFJ', 'ESFJ', 'ESTJ', 'ESTP', 'ESTP', 'ENFJ', 'ENFJ', 'ENTP', 'ESTP', 'ESTP', 'ESTJ', 'ESFJ', 'INFJ', 'ESTP', 'ESFJ', 'ESTP', 'ENFJ', 'ESTP', 'ESTJ', 'ESTJ', 'ENTJ', 'ENFJ', 'ESFJ', 'ENTJ', 'ESTJ', 'ESTP', 'ESTP', 'ENFJ', 'INFP', 'ESTJ', 'ENFJ', 'ESTJ', 'ESTJ', 'ESTJ', 'INTP', 'INTP', 'ESFJ', 'INTP', 'ESFJ', 'ESTP', 'INFP', 'ESTJ', 'ESTJ', 'ESTP', 'ESFJ', 'ESFP', 'ESTJ', 'ENTJ', 'ESTJ', 'ENFJ', 'ESTJ', 'ESFP', 'ESTJ', 'ESTP', 'ESFJ', 'ESTP', 'ESTP', 'ESTJ', 'ISFP', 'ESTJ', 'ESFJ', 'INFJ', 'ENTP', 'ESTP', 'ENFJ', 'ESTP', 'ESFP', 'ESTP', 'ESFP', 'ESTJ', 'INTP', 'ESTP', 'ISFP', 'ESTJ', 'INFP', 'ESFJ', 'ENTP', 'ENTP', 'ESTP', 'ESTP', 'ESTP', 'ESFJ', 'ESTJ', 'ESTP', 'ESFJ', 'ESTJ', 'ESTJ', 'ISFP', 'ESTJ', 'ESTJ', 'ESFJ', 'ENFJ', 'ESTP', 'ENFJ', 'ESTJ', 'ENTP', 'ENFJ', 'ESTP', 'ESTP', 'ESTJ', 'ESFJ', 'ESFJ', 'ESTJ', 'ESTJ', 'ESFJ', 'ESTJ', 'ESFJ', 'ESTP', 'ESTJ', 'ESTJ', 'ESFJ', 'ESTJ', 'INFP', 'ENTP', 'ESTP', 'ENFJ', 'ESTP', 'ISFP', 'ESFP', 'ESTJ', 'ESTJ', 'ENFJ', 'ENTJ', 'ESFJ', 'ISFP', 'ENTP', 'INFJ', 'ESFJ', 'ESTP', 'ENTP', 'ESTJ', 'ESTP', 'ENTP', 'ESFJ', 'ESTP', 'ISFP', 'ESTP', 'ESTP', 'ISFP', 'INFP', 'INFP', 'ENFJ', 'ESTP', 'INFJ', 'ENTJ', 'ESFP', 'INFJ', 'ESTJ', 'ESTP', 'ENTP', 'ESTP', 'ESTJ', 'ENTP']\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}